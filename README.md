# AudioVideoLearning

一直以来想往音视频方向学习研究一下，却苦于找不到合适的学习资料，无意之中发现《音视频开发进阶指南》一书，想着赶紧开始学习，学习不做笔记，感觉像是白学，
所以想借此把自己的学习过程记录下来，方便后续温习。

## 一、音视频基础概念

### 音频

#### 基本概念
 * 声音是由物体振动产生的；
 * 声波三要素：频率(音阶的高低)、振幅(响度)、波形(音色)；
 * 人耳听力的频率范围：20Hz ~ 20kHz；
 * 声音的传递依赖介质，真空不能传播。传播速率 固体 > 液体 > 空气；
 * 回声：声音传播过程中遇到障碍物反弹回来，再被听到；如果时间小于80毫秒，则区分不开，即听不到回声；
 * 共鸣：声音传播与是能量的传播。
 
 #### 数字音频
 
 声音模拟信号数字化的三个过程：
 
 * 采样：按比声音最高频率高2倍以上的频率对声音进行采样.(采样定理)
 * 量化：指在幅度轴上对信号进行数字化；
 * 编码：指按照一定的格式记录采样和量化后的数字数据，比如顺序存储或压缩存储等；
 
 声音的大小：

 * 音频裸数格式（Pulse Code Modulation,PCM）脉冲编码调制数据，由量化格式(sampleFormat)、采样率(sampleRate)、声道数(channel)组成，比如量化格式为16比特、采样率为44100、声道数为2，描述了CD的音质；
 * 数据比特率：即1秒时间内的比特数目，用于衡量音频数据单位时间内的容量大小，比如，CD音质的数据计算如下：
 
 ```
    44100 * 16 * 2 = 1378.125kbps，一分钟，则为 1378.125 * 60 / 8 / 1024 = 10.09MB
 ```
 
 #### 音频编码
  * 为什么要编码？ 不编码太大了，有些场景不适用，所以一般也叫压缩编码；
  * 压缩编码原理：压缩掉冗余信号。（不被人耳感知的的信号，包括人耳听觉之外和被掩蔽掉的音频信息）;
  * 压缩算法：有损压缩和无损压缩。
  
  压缩编码格式 | 说明 | 特点 | 适用场合
  -----------|------|------|------
  WAV编码 | 在PCM数据格式前加44个字节，分别描述PCM的采样率、声道数、数据格式等信息| 音质好，多软件支持 | 多媒体开发中间文件、保存音乐音效素材
  MP3编码 | LAME的中高码率编码 | 音质在128Kbits/s以上表现不错，压缩比较高，多软件硬件支持，兼容性好 | 高比特率下对兼容性有要素的音乐欣赏
  AAC编码 | 新一代音频有损压缩技术| 小于128Kbits/s码率下表现优异 | 多用于视频中音频轨的编码
  Ogg编码 | 算法出色，更小的码率达到更好的音质 | 高中低码率均表现不错，兼容性不好，不支持流媒体特性 | 语言聊天的音频消息场景
  

### 视频

#### 图像的数值表示

 * RGB 表示方式
    计算一张1280 * 720 的RGBA_8888图像的大小，如下方式：
    
 ```
   1280 * 720 * 4 = 3.516MB
 ```
    
 * YUV 表示方式
   主要用于彩色视频信号的传输，使其向后兼容老式黑白电视，最大优点：占用极少的频宽；
   Y ，表示明亮度，U、V表示的则是色度；
   常用的采样格式是 4 ：2 ：0，对于一帧为1280 * 720 的视频帧，用YUV420P格式表示如下：
   
       
     ```
       1280 * 720 * 1 + 1280 * 720 * 0.5 = 1.318MB
       如果fps 为24 ，电影长度90分钟，则YUV420P格式，数据量大小如下：
       1.318MB * 24fps * 90 min * 60s = 166.8GB
       还是好大，还要压缩。
       
     ```
#### 视频编码方式
 1.压缩原理：去除空间和时间上的冗余信息；
  
 （1）帧间编码技术，去除时间冗余信息：
 
 * 运动补偿： 先前局部图像来预测、补偿当前的局部图像，减少帧序列冗余的有效方法；
 * 运动表示：不同区域的图像用不同的运动矢量来描述运动信息；
 * 运动估计：从视频序列中抽取运动信息的一整套技术；
 
 （2）帧内编码，去除空间冗余信息：
 * MPEG算法，适用动态视频的压缩算法；
 * H.264算法，设计简洁，压缩性能提高、系统更加完善；
 
 2.编码概念
 
 * IPB帧
 
 帧名 | 说明 | 作用
 -----|-----|-----
 I帧 | 帧内编码帧 | 通常为每个GOP的第一帧，经过适当压缩，作为随机访问的参考点，压缩比可达6 ：1，去除空间冗余
 P帧 | 前向预测编码帧 | 参考前面的I帧或P帧，来解码压缩视频画面，去除时间冗余
 B帧 | 双向预测内插编码帧 | 参考前面的I帧或P帧，又顾及后面的P帧，来解码压缩视频画面，去除时间冗余。
 
 H264 IDR帧与I帧的区别，在于H264采用了多帧预测，所以I帧以后的P帧有可能会参考I帧以前的的帧，导致解析不出来，所以在遇到IDR帧将清除参考帧缓冲区，以IDR帧作为被参考的帧；
 
 
 * PTS 与 DTS
 
 在有B帧情况下，两都输出顺序不一样；
 
 DTS(Decoding Time Stamp) | 用于视频解码  
  -----|-----
  PTS(Presentation Time Stamp) | 用于解码阶段进行视频的同步和输出
  
  * GOP （Group Of Picture）
  两个I帧之间的一组图片,必须要设置 gop_size，值越大，画面质量越好。提高视频质量技巧，多使用B帧，I的压缩比 7， P是20，B可以达到50，用B帧节省的空间可以用来更多保存I帧，这样就能在相册码率下提供更好画质。
 

## 二、移动环境搭建

### 1. jni调用native方法

音视频开发不可避免要用到native的方法，掌握jni与native的调用，至关重要。代码可以在jnidemo包下查看。
android jni调用native方法主要步骤如下：
 * 1.新建一个JAVA类，里面定义一个native方法；
 * 2.cd到类所有的目录，调用如下命令，便可以生成相应的class文件和.h文件,注意之前的javah命令已经在java 10 中移除。
 
 ```
     javac -h ./ TestEncoder.java

 ```
 * 3.生成之后，main下面新建jni文件夹，并将上一步成功的.h文件移动过去；
 
 * 4.jni目录下，新建一个.cpp文件，同时实现.h文件中的方法，当然要把头文件导入进来，如下
 
  ```
      #include "com_zxh_audiovideolearning_jnidemo_Mp3Encoder.h"
      
      JNIEXPORT jstring JNICALL Java_com_zxh_audiovideolearning_jnidemo_Mp3Encoder_encode
        (JNIEnv *env, jobject instance){
      
        return (*env) -> NewStringUTF("I am encoder from C");
      
      }
 
  ```
  * 5.jni目录再新建一个 Android.mk文件，这个文件主要配置生成库的一些基本信息，如下：
  
 ```
     LOCAL_PATH := $(call my-dir)                   //返回当前文件在系统中的路径，必须一开始就定义
     include $(CLEAR_VARS)                          //清除上一次构建过程中的所有全局变量
     LOCAL_LDLIBS := -L$(SYSROOT)/usr/lib -llog     //NDK编译过程中所依赖的NDK提供的动态与静态为库，在ndk/platforms/android-18/下面有很多库
     LOCAL_MODULE := libaudioencoder                //本模块编译的目标名，唯一且不含空格，如果是so库则是编译生成的名称就是 lib项目名.so
     LOCAL_SRC_FILES = ./Mp3Encoder.cpp             //要编译的c 或者cpp文件
     include $(BUILD_SHARED_LIBRARY)                //系统提供的内置变量，表示构建的是动态库，在ndk/build/core目录下还有其它内置变量

 ```

 * 6.接下来就是要生成动态库了，在当前目录下，执行 ndk-build 就会在jni同级目录下生成libs、obj文件夹，里面有arm64-v8a、armeabi-v7a、x86、x86_64架构下的so库
 
 * 7.接着，在main目录下，新建一个jniLibs目录，将libs下面的文件夹移动到此目录。试过在build.gradle中配置jniLibs目录为libs，但测试过程中发现会崩溃，提示找不到so库
 
 * 8.最后，在调用的activity 中用静态代码块将so库加载进来，接着，便可以调用native的方法了。
  
 ```
    /**
     * 加载编译好动态so库
    */
    static {
        System.loadLibrary("audioencoder");
    }
 ```
### 2. 交叉编译







